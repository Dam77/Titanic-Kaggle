{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11021400,"sourceType":"datasetVersion","datasetId":6863016}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Loading Dataset using pandas library\ntrain = pd.read_csv(\"/kaggle/input/titanicdataset/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanicdataset/test.csv\")\n\n# Checking data (Important to understand the context)\nprint(train.head())\nprint(train.info())\nprint(train.describe())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-13T23:08:03.388375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"#Checking if there's missing data\nprint(train.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are missing values in age, Cabin and Embarked\n\n* Age has 177 missed values which is relatively few, we can replace them with the median.\n* Cabin has 687 missed values out of 891 which is too many. I think it makes sense to remove this column.\n* Embarked has 2 missed values. That's negligible, we can replace it by the mode (most frequent category)","metadata":{}},{"cell_type":"markdown","source":"**Replacing Age by its median :**\nAnd why not use the mean ? because the mean is sensitive to extreme values.The Median is more similar to the population","metadata":{}},{"cell_type":"code","source":"# Replacing age missing values by its median\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n\n# Also the same to test.csv\ntest[\"Age\"] = test[\"Age\"].fillna(train[\"Age\"].median())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Removing Cabin due to excessive missing values** And why removing it ? Because over 75% of the values are missing, making the feature useless for the prediction.","metadata":{}},{"cell_type":"code","source":"# Removing Cabin's column from train and test data frame\ntrain = train.drop(columns=[\"Cabin\"])\ntest = test.drop(columns=[\"Cabin\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Remplacing Embarked by its most frequent value** And why ? Since Embarked only has 3 possible values,  We'll replace it with the most frequent category (mode) to ensures minimal impact on the dataset","metadata":{}},{"cell_type":"code","source":"# Replacing Embarked missing values by its mode\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0])\n\n# Same for test data frame\ntest[\"Embarked\"] = test[\"Embarked\"].fillna(test[\"Embarked\"].mode()[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replacing one passenger fare missing value test data frame\ntest[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Checking if Data cleaning worked**","metadata":{}},{"cell_type":"code","source":"print(train.isnull().sum())\nprint(test.isnull().sum())\n# We can see that there are are no more missing values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Machine Learning systems can not read and understand datatypes like String. So we must transform our data to numeric types.","metadata":{}},{"cell_type":"code","source":"# Remember which data need to be transformed to be understood by Machine Learning systems\nprint(train.dtypes)\nprint(test.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"We need to convert 'Sex', 'Embarked' and 'Pclass' into numerical representations that our model can process","metadata":{}},{"cell_type":"code","source":"# Sex (into binary)\ntrain[\"Sex\"] = train[\"Sex\"].map({\"male\": 0, \"female\": 1})\ntest[\"Sex\"] = test[\"Sex\"].map({\"male\": 0, \"female\": 1})\nprint(train[\"Sex\"].head())\nprint(test[\"Sex\"].head())\nprint(train.head())\nprint(test.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Embarked (One hot encoding)\n# => Creating separate binary columns, because none of the 3 possible values is better than the others\ntrain = pd.get_dummies(train, columns=[\"Embarked\"], drop_first=True)\ntest = pd.get_dummies(test, columns=[\"Embarked\"], drop_first=True)\nprint(test.head())\nprint(test.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# What Name column looks like ?\nprint(train[\"Name\"])\n\n# We notice that even if the name doesn't mean anything to predict if a passenger will survive, we still can extract \"Mrs.\", \"Miss.\" etc. This could improve our model.\n\n# We will first extract the title by creating a new column\ntrain[\"Title\"] = train[\"Name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(\"([A-Za-z]+)\\.\", expand=False)\nprint(train[\"Title\"])\nprint(train[\"Name\"])\n\n# As we can see, we now get a new column named \"Title\". I extracted the name before \".\" thank to \"\\.\" in the previous code","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train.head())\n# We notice that we see for the first one \"Mr\", then \"Mrs\" for the second... So it worked!\n\nprint(train[\"Title\"].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Titles like Jonkheer, Don, Mme, Lady… appear only once. All these rare titles will be grouped under the same name.","metadata":{}},{"cell_type":"code","source":"title_mapping = {\n    \"Mr\" : \"Mr\", \"Miss\" : \"Miss\", \"Mrs\" : \"Mrs\", \"Master\" : \"Master\", \"Dr\" : \"Dr\", \"Rev\" : \"Rare\", \"Mlle\" : \"Rare\", \"Major\" : \"Rare\", \"Col\" : \"Rare\", \"Countess\" : \"Rare\", \"Capt\" : \"Rare\", \"Ms\" : \"Rare\", \"Sir\" : \"Rare\", \"Lady\" : \"Rare\", \"Mme\" : \"Rare\", \"Don\" : \"Rare\", \"Jonkheer\" : \"Rare\"\n}\ntrain[\"Title\"] = train[\"Title\"].map(title_mapping)\ntest[\"Title\"] = test[\"Title\"].map(title_mapping)\nprint(train[\"Title\"].value_counts())\nprint(train[\"Title\"].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking if our dataset is still logic as usual, using head or columns pandas methods\nprint(train.columns)\nprint(train.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Looks great, now we need to do a \"one-hot encode\" of the Title column\n\ntrain = pd.get_dummies(train, columns=[\"Title\"], drop_first=True)\ntest = pd.get_dummies(test, columns=[\"Title\"], drop_first=True)\nprint(train.columns)\nprint(test.columns)\nprint(train.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Our Dataset is ready because PassengerId, Ticket and Name column won't be used in the model (They are going to be removed next). So all the data are numeric and can be trained by the model.","metadata":{}},{"cell_type":"code","source":"# Keeping PassengerId that will be useful to create submission.csv later\ntest_ID = test[\"PassengerId\"]\n\n# Removing useless columns\ntrain = train.drop(columns=[\"Name\", \"Ticket\", \"PassengerId\"])\ntest = test.drop(columns=[\"Name\", \"Ticket\", \"PassengerId\"])\n\nprint(train.dtypes)\nprint(test.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting Data : Training and Validation Sets","metadata":{}},{"cell_type":"markdown","source":"To evaluate our model properly, we divide the dataset into a training set (80%) and a validation set (20%).","metadata":{}},{"cell_type":"code","source":"X_train = train.drop(columns=[\"Survived\"])\nY_train = train[\"Survived\"]\nprint(Y_train.head())\nprint(X_train.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Spliting (80-20)\nX_train_sub, X_val, Y_train_sub, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n# Why 42 ? Meaning of life !","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"Why ? Simple and Efficient for Binary classification","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Model initiation\nmodel = LogisticRegression(max_iter=1200)\n\n# Training on sub data\nmodel.fit(X_train_sub, Y_train_sub)\n\n# Prediction on val data\nY_pred = model.predict(X_val)\n\n# Exam\naccuracy = accuracy_score(Y_val, Y_pred)\nprint(f\"Precision du modèl : {accuracy}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I'm happy to get 81,5%. I'll consider this model as successfull","metadata":{}},{"cell_type":"code","source":"# Checking is test file is comparable to the one we used.\nprint(test.shape)\nprint(X_train_sub.shape)\nprint(test.columns)\nprint(X_train_sub.columns)\n\n# Same columns, looks good","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modelising\nY_test_pred = model.predict(test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating gender_submission.csv\nsubmission = pd.DataFrame({\n    \"PassengerID\" : test_ID,\n    \"Survived\" : Y_test_pred\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}